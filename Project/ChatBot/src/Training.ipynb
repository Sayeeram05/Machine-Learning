{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e9771f0-e266-4d84-8058-c1edb58d7899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b089ecc-f6b0-41ec-a66c-e29b6ff3ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run NLTK.ipynb import Tokenize,LoweringStemming,BagOfWord  # Use %run to import other jupyte notebook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b748ae07-0e43-4ffe-83f3-1abdde61bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AllWords = []\n",
    "Tags = []\n",
    "XY = []\n",
    "\n",
    "XTrain = []\n",
    "YTrain = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b55464f8-1957-41d5-85a9-9d4c574992af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'greeting',\n",
       "   'patterns': ['Hi',\n",
       "    'Hey',\n",
       "    'How are you',\n",
       "    'Is anyone there?',\n",
       "    'Hello',\n",
       "    'Good day'],\n",
       "   'responses': ['Hey :-)',\n",
       "    'Hello, thanks for visiting',\n",
       "    'Hi there, what can I do for you?',\n",
       "    'Hi there, how can I help?']},\n",
       "  {'tag': 'goodbye',\n",
       "   'patterns': ['Bye', 'See you later', 'Goodbye'],\n",
       "   'responses': ['See you later, thanks for visiting',\n",
       "    'Have a nice day',\n",
       "    'Bye! Come back again soon.']},\n",
       "  {'tag': 'thanks',\n",
       "   'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"],\n",
       "   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n",
       "  {'tag': 'items',\n",
       "   'patterns': ['Which items do you have?',\n",
       "    'What kinds of items are there?',\n",
       "    'What do you sell?'],\n",
       "   'responses': ['We sell coffee and tea', 'We have coffee and tea']},\n",
       "  {'tag': 'payments',\n",
       "   'patterns': ['Do you take credit cards?',\n",
       "    'Do you accept Mastercard?',\n",
       "    'Can I pay with Paypal?',\n",
       "    'Are you cash only?'],\n",
       "   'responses': ['We accept VISA, Mastercard and Paypal',\n",
       "    'We accept most major credit cards, and Paypal']},\n",
       "  {'tag': 'delivery',\n",
       "   'patterns': ['How long does delivery take?',\n",
       "    'How long does shipping take?',\n",
       "    'When do I get my delivery?'],\n",
       "   'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']},\n",
       "  {'tag': 'funny',\n",
       "   'patterns': ['Tell me a joke!',\n",
       "    'Tell me something funny!',\n",
       "    'Do you know a joke?'],\n",
       "   'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.',\n",
       "    'What did the buffalo say when his son left for college? Bison.']}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"intents.json\", \"r\") as F:\n",
    "    intents = json.load(F)\n",
    "intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29edfd82-11d1-4b77-85cb-09791b4df5db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi']\n",
      "['hey']\n",
      "['how', 'are', 'you']\n",
      "['is', 'anyon', 'there']\n",
      "['hello']\n",
      "['good', 'day']\n",
      "['bye']\n",
      "['see', 'you', 'later']\n",
      "['goodby']\n",
      "['thank']\n",
      "['thank', 'you']\n",
      "['that', 'help']\n",
      "['thank', 'a', 'lot']\n",
      "['which', 'item', 'do', 'you', 'have']\n",
      "['what', 'kind', 'of', 'item', 'are', 'there']\n",
      "['what', 'do', 'you', 'sell']\n",
      "['do', 'you', 'take', 'credit', 'card']\n",
      "['do', 'you', 'accept', 'mastercard']\n",
      "['can', 'i', 'pay', 'with', 'paypal']\n",
      "['are', 'you', 'cash', 'onli']\n",
      "['how', 'long', 'doe', 'deliveri', 'take']\n",
      "['how', 'long', 'doe', 'ship', 'take']\n",
      "['when', 'do', 'i', 'get', 'my', 'deliveri']\n",
      "['tell', 'me', 'a', 'joke']\n",
      "['tell', 'me', 'someth', 'funni']\n",
      "['do', 'you', 'know', 'a', 'joke']\n",
      "AllWords :  ['a', 'accept', 'anyon', 'are', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'deliveri', 'do', 'doe', 'funni', 'get', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you']\n",
      "XY :  [(['hi'], 'greeting'), (['hey'], 'greeting'), (['how', 'are', 'you'], 'greeting'), (['is', 'anyon', 'there'], 'greeting'), (['hello'], 'greeting'), (['good', 'day'], 'greeting'), (['bye'], 'goodbye'), (['see', 'you', 'later'], 'goodbye'), (['goodby'], 'goodbye'), (['thank'], 'thanks'), (['thank', 'you'], 'thanks'), (['that', 'help'], 'thanks'), (['thank', 'a', 'lot'], 'thanks'), (['which', 'item', 'do', 'you', 'have'], 'items'), (['what', 'kind', 'of', 'item', 'are', 'there'], 'items'), (['what', 'do', 'you', 'sell'], 'items'), (['do', 'you', 'take', 'credit', 'card'], 'payments'), (['do', 'you', 'accept', 'mastercard'], 'payments'), (['can', 'i', 'pay', 'with', 'paypal'], 'payments'), (['are', 'you', 'cash', 'onli'], 'payments'), (['how', 'long', 'doe', 'deliveri', 'take'], 'delivery'), (['how', 'long', 'doe', 'ship', 'take'], 'delivery'), (['when', 'do', 'i', 'get', 'my', 'deliveri'], 'delivery'), (['tell', 'me', 'a', 'joke'], 'funny'), (['tell', 'me', 'someth', 'funni'], 'funny'), (['do', 'you', 'know', 'a', 'joke'], 'funny')]\n"
     ]
    }
   ],
   "source": [
    "for intent in intents[\"intents\"]:\n",
    "    Tag = intent[\"tag\"]\n",
    "    Tags.append(Tag)\n",
    "    for Pattern in intent[\"patterns\"]:\n",
    "        Words = Tokenize(Pattern)\n",
    "        Words = [LoweringStemming(Stem) for Stem in Words if(Stem not in [\"?\",\"!\",\".\",\",\",\"'s\"])]\n",
    "        AllWords.extend(Words)  #Words is a list\n",
    "        XY.append((Words,Tag))\n",
    "        print(Words)\n",
    "\n",
    "AllWords = sorted(set(AllWords)) #Set() for remove duplicate\n",
    "print(\"AllWords : \",AllWords)\n",
    "print(\"XY : \",XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d15d40a0-23a7-4cc1-b9d9-7690fc8eda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for (Pattern,Tag) in XY:\n",
    "    XTrain.append(BagOfWord(Pattern,AllWords))\n",
    "    YTrain.append(Tags.index(Tag))  \n",
    "XTrain = np.array(XTrain)\n",
    "YTrain = np.array(YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "250d9d95-b2d0-4a6e-9973-6f2c2028ea6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59087afd-cd89-4f12-99a9-af79755752cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5,\n",
       "       5, 6, 6, 6])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f1c6571-60c5-45be-af76-3f9c69df7fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "class ChatDataset(Dataset):\n",
    "    # def __init__(self):\n",
    "    #     self.NSample = len(XTrain)\n",
    "    #     self.XData = XTrain\n",
    "    #     self.YData = YTrain\n",
    "\n",
    "    # def __getitem__(self,index):\n",
    "    #     return self.XData[index],self.YData[index]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.NSample = len(XTrain)\n",
    "        self.XData = XTrain.astype(np.float32)  # Ensure the correct dtype\n",
    "        self.YData = YTrain\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.from_numpy(self.XData[index])\n",
    "        y = torch.tensor(self.YData[index], dtype=torch.long)  # Ensure correct dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.NSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db481a66-6536-4425-9adf-a6579cfd6a57",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'freeze_support' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m DataSet \u001b[38;5;241m=\u001b[39m ChatDataset()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mfreeze_support\u001b[49m()\n\u001b[0;32m      5\u001b[0m TrainLoader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mDataSet, batch_size\u001b[38;5;241m=\u001b[39mBatchSize, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(TrainLoader)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'freeze_support' is not defined"
     ]
    }
   ],
   "source": [
    "BatchSize = 8\n",
    "DataSet = ChatDataset()\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "TrainLoader = DataLoader(dataset=DataSet, batch_size=BatchSize, shuffle=True)\n",
    "print(TrainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c1d686f-0d6f-4212-ba18-a99e8f2be0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Model.ipynb import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6c8518b-f682-473a-b050-b0833fe6a332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 8 7\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "InputSize = len(AllWords)\n",
    "HiddenSize = 8 \n",
    "NumClasses = len(Tags)\n",
    "print(InputSize, HiddenSize, NumClasses)\n",
    "\n",
    "Device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Model = NeuralNet(InputSize, HiddenSize, NumClasses).to(Device)\n",
    "print(Device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65c1be40-30fb-473a-a4ae-eb849d533a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data type: <class 'numpy.ndarray'>\n",
      "x_data[index] type: <class 'numpy.ndarray'>\n",
      "x_data[index] shape: (54,)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m Optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(Model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLearningRate)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Epochs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NumEpochs):\n\u001b[1;32m----> 8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mWords\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTrainLoader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mWords\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mWords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m   \u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ChatBot\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ChatBot\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ChatBot\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[46], line 78\u001b[0m, in \u001b[0;36mChatDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_data[index] type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_data[index])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_data[index] shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_data[index]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 78\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_data[index], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "\n",
    "LearningRate = 0.001\n",
    "NumEpochs = 1000\n",
    "\n",
    "Criterian = nn.CrossEntropyLoss()\n",
    "Optimizer = torch.optim.Adam(Model.parameters(), lr=LearningRate)\n",
    "\n",
    "for Epochs in range(NumEpochs):\n",
    "    for (Words,Labels) in TrainLoader:\n",
    "        Words = Words.to(Device)\n",
    "        Labels = Labels.to(device).long()   \n",
    "\n",
    "        Output = Model(Words)\n",
    "        Loss = Criterian(Output, Labels)\n",
    "\n",
    "        Optimizer.zero_grad()\n",
    "        Loss.backward()\n",
    "        Optimizer.step()\n",
    "\n",
    "    if(Epochs + 1) % 100 == 0 :\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85115f-676a-4342-8003-e6335a998cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
